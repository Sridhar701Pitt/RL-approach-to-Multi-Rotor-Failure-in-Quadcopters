# docker build command
docker build -t python3:gympybullet_gcp .

docker run -it --rm --privileged --net=host --env-file ./.env -v /tmp/.X11-unix:/tmp/.X11-unix:rw -v "$(pwd)":/root/Python_ws --gpus all --shm-size=5.00gb python3:gympybullet_gcp
# --shm-size param in the above command increases shared memory to 5gb for ray rllib performance
# Useful Docker commands
# Setting envs
#ENV TURTLEBOT3_MODEL=burger
#RUN echo "source /opt/ros/melodic/setup.bash" >> ~/.bashrc

#  after running container
pip3 install -e .
python trainers/hover_learn_gcp_sac.py

## Changes to note
#this added to etc/profile to enable docker access to xhost display
if [ "$DISPLAY" != "" ]
then
  xhost +local:docker
fi


#export variables
export PROJECT_ID=$(gcloud config list project --format "value(core.project)")
export IMAGE_REPO_NAME=pybullet_drones_custom_container
export IMAGE_TAG=pybullet_drones_sac_hover
export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG

# bucket commands
BUCKET_NAME=${PROJECT_ID}-pybullet-test
REGION=us-central1
# Create the bucket
gsutil mb -l $REGION gs://$BUCKET_NAME

#build docker file
docker build -f Dockerfile -t $IMAGE_URI ./

#push docker image to cloud
docker push $IMAGE_URI

#define env variables
export MODEL_DIR=hover_taskII_10Mt_Sfail_ppo_gpu_$(date +%Y%m%d_%H%M%S)
export REGION=us-central1
export JOB_NAME=hover_taskII_10Mt_Sfail_ppo_gpu_$(date +%Y%m%d_%H%M%S)

# For local testing
#run locally first IMAGEURI=gcr.io/potent-arcade-341204/pybullet_drones_custom_container:pybullet_drones_cpu
# docker run --shm-size=5.03gb $IMAGE_URI --num_workers 4 --episodes 5
# docker run --shm-size=5.03gb $IMAGE_URI --gcp True --model-dir gs://$BUCKET_NAME/$MODEL_DIR --steps 10000

#Submit the job
gcloud ai-platform jobs submit training $JOB_NAME \
  --region $REGION \
  --master-image-uri $IMAGE_URI \
  --scale-tier BASIC \
  -- \
  --model-dir=gs://$BUCKET_NAME/$MODEL_DIR \
  --gcp=True \
  --steps=10000

# SAc
gcloud ai-platform jobs submit training $JOB_NAME \
  --region $REGION \
  --master-image-uri $IMAGE_URI \
  --scale-tier BASIC \
  -- \
  --model-dir=gs://$BUCKET_NAME/$MODEL_DIR \
  --gcp=True \
  --steps=10000 

# SAc - GPU
gcloud ai-platform jobs submit training $JOB_NAME \
  --region $REGION \
  --master-image-uri $IMAGE_URI \
  --scale-tier BASIC_GPU \
  -- \
  --model-dir=gs://$BUCKET_NAME/$MODEL_DIR \
  --gcp=True \
  --env=singlerotor \
  --algo=sac \
  --steps=10000000 

# SAc - CUSTOM
gcloud ai-platform jobs submit training $JOB_NAME \
  --region $REGION \
  --master-image-uri $IMAGE_URI \
  --scale-tier custom \
  --master-machine-type n1-highcpu-16 \
  -- \
  --model-dir=gs://$BUCKET_NAME/$MODEL_DIR \
  --gcp=True \
  --steps=10000


#monitor jobs and stream logs
gcloud ai-platform jobs describe $JOB_NAME
gcloud ai-platform jobs stream-logs $JOB_NAME



# SIngle past
docker build -t python3:gympybullet_gcp .

docker run -it --rm --privileged --net=host --env-file ./.env -v /tmp/.X11-unix:/tmp/.X11-unix:rw -v "$(pwd)":/root/Python_ws --gpus all --shm-size=5.00gb python3:gympybullet_gcp

#export variables
export PROJECT_ID=$(gcloud config list project --format "value(core.project)")
export IMAGE_REPO_NAME=pybullet_drones_custom_container
export IMAGE_TAG=pybullet_drones_sac_hover
export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG

# bucket commands
BUCKET_NAME=${PROJECT_ID}-pybullet-test
REGION=us-central1

#build docker file
docker build -f Dockerfile -t $IMAGE_URI ./

#push docker image to cloud
docker push $IMAGE_URI

#define env variables
export MODEL_DIR=hover_taskIII_10Mt_DfailOpp_sac_gpu_$(date +%Y%m%d_%H%M%S)
export REGION=us-central1
export JOB_NAME=hover_taskII_10Mt_DfailOpp_sac_gpu_$(date +%Y%m%d_%H%M%S)

# SAc - GPU
gcloud ai-platform jobs submit training $JOB_NAME \
  --region $REGION \
  --master-image-uri $IMAGE_URI \
  --scale-tier BASIC_GPU \
  -- \
  --model-dir=gs://$BUCKET_NAME/$MODEL_DIR \
  --gcp=True \
  --env=singlerotor \
  --algo=sac \
  --steps=10000000